#!/usr/bin/env python3
"""
detectree2_infer_instances_ENHANCED_FIXED.py
Optimierte Inferenz mit automatischer Bildgr√∂√üen-Begrenzung
"""

import os
import numpy as np
import cv2
import torch
import rasterio
from rasterio.transform import Affine
import geopandas as gpd
from shapely.geometry import Polygon, MultiPolygon
from shapely.ops import unary_union
from shapely.validation import make_valid
import warnings
warnings.filterwarnings('ignore')

from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog

# ===========================================
# üîß Konfiguration
# ===========================================
BASE_DIR = "/home/abrax/detectree2/training"

# ANPASSEN: Pfad zu deinem trainierten Modell
MODEL_PATH = os.path.join(BASE_DIR, "outputs_single_class_with_final/model_final.pth")

# Input und Output
INPUT_IMAGE = os.path.join(BASE_DIR, "images", "martel_rgb.tif")
OUTPUT_GPKG = os.path.join(BASE_DIR, "result_martel_rgb.gpkg") ##
OUTPUT_VISUAL = os.path.join(BASE_DIR, "detection_visualization.jpg") ##

# Inference-Parameter
SCORE_THRESHOLD = 0.6
NMS_THRESHOLD = 0.4
MAX_DETECTIONS = 1000

# KRITISCH: Maximale Bildgr√∂√üe begrenzen
MAX_IMAGE_SIZE = 1000  # Max. 4000 Pixel pro Seite f√ºr RAM-Management

# Polygon-Verarbeitung
MIN_AREA = 3.0
SIMPLIFY_TOLERANCE = 0.3

print(f"üéØ Enhanced Tree Crown Detection (RAM-optimiert)")
print(f"üìÇ Modell: {MODEL_PATH}")
print(f"üñºÔ∏è Input: {INPUT_IMAGE}")
print(f"üìä Score Threshold: {SCORE_THRESHOLD}")
print(f"üîç Max Detections: {MAX_DETECTIONS}")
print(f"üìê Max Image Size: {MAX_IMAGE_SIZE}px")

# ===========================================
# ü§ñ Modell laden
# ===========================================
def setup_predictor():
    """Predictor f√ºr optimierte Kronenerkennung einrichten"""
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
    
    # Single-Class Setup
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
    cfg.MODEL.WEIGHTS = MODEL_PATH
    cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Reduzierte Input-Gr√∂√üen f√ºr RAM-Management
    cfg.INPUT.MIN_SIZE_TEST = 600
    cfg.INPUT.MAX_SIZE_TEST = MAX_IMAGE_SIZE
    
    # Erweiterte Detection-Parameter
    cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 6000
    cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 2000
    cfg.MODEL.RPN.NMS_THRESH = 0.6
    cfg.MODEL.RPN.SCORE_THRESH_TEST = 0.0
    
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = SCORE_THRESHOLD
    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = NMS_THRESHOLD
    cfg.TEST.DETECTIONS_PER_IMAGE = MAX_DETECTIONS
    
    # Metadata f√ºr Single-Class
    MetadataCatalog.get("tree_inference").set(thing_classes=["tree"])
    cfg.DATASETS.TEST = ("tree_inference",)
    
    return DefaultPredictor(cfg)

print("üîß Lade Modell...")
predictor = setup_predictor()
print(f"‚úÖ Modell geladen auf: {predictor.cfg.MODEL.DEVICE}")

# ===========================================
# üìç Bild laden und ggf. verkleinern
# ===========================================
print("üìñ Lade und verarbeite Eingangsbild...")
with rasterio.open(INPUT_IMAGE) as src:
    original_transform = src.transform
    original_crs = src.crs
    original_width = src.width
    original_height = src.height
    
    print(f"üìê Original-Bildgr√∂√üe: {original_width} √ó {original_height}")
    
    # Berechne Skalierungsfaktor
    max_dim = max(original_width, original_height)
    if max_dim > MAX_IMAGE_SIZE:
        scale_factor = MAX_IMAGE_SIZE / max_dim
        new_width = int(original_width * scale_factor)
        new_height = int(original_height * scale_factor)
        print(f"üìâ Skaliere auf: {new_width} √ó {new_height} (Faktor: {scale_factor:.3f})")
        
        # Resample mit rasterio
        from rasterio.enums import Resampling
        image_rgb = src.read(
            out_shape=(src.count, new_height, new_width),
            resampling=Resampling.bilinear
        ).transpose(1, 2, 0)
        
        # Angepassten Transform berechnen
        transform = original_transform * original_transform.scale(
            original_width / new_width,
            original_height / new_height
        )
        
    else:
        # Keine Skalierung n√∂tig
        scale_factor = 1.0
        new_width, new_height = original_width, original_height
        image_rgb = src.read([1, 2, 3]).transpose(1, 2, 0)
        transform = original_transform
        print(f"‚úÖ Bildgr√∂√üe OK, keine Skalierung n√∂tig")

print(f"üìê Finale Bildgr√∂√üe f√ºr Inferenz: {new_width} √ó {new_height}")
print(f"üó∫Ô∏è CRS: {original_crs}")

# Konvertiere zu BGR f√ºr OpenCV/Detectron2
image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)

# ===========================================
# üîç Inferenz durchf√ºhren
# ===========================================
print("üöÄ Starte Kronenerkennung...")
with torch.no_grad():
    torch.cuda.empty_cache()
    outputs = predictor(image_bgr)

instances = outputs["instances"].to("cpu")
num_detections = len(instances)
print(f"üéØ {num_detections} Kronen erkannt")

if num_detections == 0:
    print("‚ùå Keine Kronen erkannt!")
    exit(1)

# ===========================================
# üìä Detections analysieren
# ===========================================
scores = instances.scores.numpy()
masks = instances.pred_masks.numpy()
boxes = instances.pred_boxes.tensor.numpy()

print(f"üìà Score-Statistiken:")
print(f"   Min: {scores.min():.3f}")
print(f"   Max: {scores.max():.3f}")
print(f"   Median: {np.median(scores):.3f}")
print(f"   √úber {SCORE_THRESHOLD}: {(scores >= SCORE_THRESHOLD).sum()}")

# ===========================================
# üó∫Ô∏è Masken zu Polygonen konvertieren (mit Skalierung)
# ===========================================
def mask_to_polygon(mask, transform, scale_factor, min_area=MIN_AREA):
    """Konvertiert Maske zu georeferenziertem Polygon"""
    contours, _ = cv2.findContours(
        mask.astype(np.uint8),
        cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE
    )
    
    polygons = []
    for contour in contours:
        if len(contour) < 4:
            continue
            
        # Pixelkoordinaten zu Weltkoordinaten (mit R√ºckskalierung!)
        world_coords = []
        for point in contour.reshape(-1, 2):
            # R√ºckskalierung zu Original-Pixelkoordinaten
            x_pixel = float(point[0]) / scale_factor
            y_pixel = float(point[1]) / scale_factor
            
            # Weltkoordinaten mit Original-Transform
            x_world, y_world = original_transform * (x_pixel, y_pixel)
            world_coords.append((x_world, y_world))
        
        if len(world_coords) >= 3:
            try:
                poly = Polygon(world_coords)
                poly = make_valid(poly)
                
                if poly.is_valid and poly.area >= min_area:
                    if SIMPLIFY_TOLERANCE > 0:
                        poly = poly.simplify(SIMPLIFY_TOLERANCE, preserve_topology=True)
                    polygons.append(poly)
            except Exception as e:
                continue
    
    return polygons

print("üîÑ Konvertiere Masken zu Polygonen...")
all_polygons = []
all_scores = []
all_areas = []

for i in range(num_detections):
    mask = masks[i]
    score = scores[i]
    
    polygons = mask_to_polygon(mask, transform, scale_factor)
    
    for poly in polygons:
        all_polygons.append(poly)
        all_scores.append(score)
        all_areas.append(poly.area)

print(f"‚úÖ {len(all_polygons)} g√ºltige Polygone erstellt")

if len(all_polygons) == 0:
    print("‚ùå Keine g√ºltigen Polygone!")
    exit(1)

# ===========================================
# üìä Polygon-Statistiken
# ===========================================
areas = np.array(all_areas)
scores_array = np.array(all_scores)

print(f"üìê Fl√§chen-Statistiken (m¬≤):")
print(f"   Min: {areas.min():.2f}")
print(f"   Max: {areas.max():.2f}")
print(f"   Median: {np.median(areas):.2f}")
print(f"   Gesamt: {areas.sum():.2f}")

# ===========================================
# üíæ GeoPackage speichern
# ===========================================
print("üíæ Speichere Ergebnisse...")

gdf = gpd.GeoDataFrame({
    'geometry': all_polygons,
    'confidence': all_scores,
    'area_m2': all_areas,
    'tree_id': range(1, len(all_polygons) + 1),
    'detection_class': ['tree'] * len(all_polygons),
    'scale_factor': [scale_factor] * len(all_polygons)
}, crs=original_crs)

# Nach Confidence sortieren
gdf = gdf.sort_values('confidence', ascending=False).reset_index(drop=True)

# Speichern
gdf.to_file(OUTPUT_GPKG, driver='GPKG')
print(f"‚úÖ {len(gdf)} Kronen gespeichert: {OUTPUT_GPKG}")

# ===========================================
# üé® Visualisierung erstellen (auf skaliertem Bild)
# ===========================================
print("üé® Erstelle Visualisierung...")

v = Visualizer(
    image_rgb[:, :, ::-1],
    MetadataCatalog.get("tree_inference"),
    scale=0.8,
    instance_mode=ColorMode.IMAGE
)

vis = v.draw_instance_predictions(outputs["instances"].to("cpu"))
vis_image = vis.get_image()[:, :, ::-1]

cv2.imwrite(OUTPUT_VISUAL, vis_image)
print(f"üì∏ Visualisierung gespeichert: {OUTPUT_VISUAL}")

# ===========================================
# üìã Zusammenfassung
# ===========================================
print("\nüéØ === ERGEBNISSE ===")
print(f"üìä Erkannte Kronen: {len(gdf)}")
print(f"üìà Durchschnittliche Confidence: {scores_array.mean():.3f}")
print(f"üìê Durchschnittliche Fl√§che: {areas.mean():.2f} m¬≤")
print(f"üå≥ Gesamte Kronenfl√§che: {areas.sum():.2f} m¬≤")
print(f"üìè Skalierungsfaktor: {scale_factor:.3f}")
print(f"üíæ Output: {OUTPUT_GPKG}")
print(f"üñºÔ∏è Visualisierung: {OUTPUT_VISUAL}")

high_conf = gdf[gdf['confidence'] >= 0.7]
print(f"‚≠ê Hohe Confidence (‚â•0.7): {len(high_conf)} Kronen")

print("\n‚úÖ Inferenz erfolgreich abgeschlossen!")
torch.cuda.empty_cache()

